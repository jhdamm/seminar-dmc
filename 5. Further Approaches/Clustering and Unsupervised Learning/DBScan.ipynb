{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "njobs = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('../../1. Task and Data/train.csv',sep='|')\n",
    "test=pd.read_csv('../../1. Task and Data/test.csv',sep='|')\n",
    "test = test.sample(1000);\n",
    "\n",
    "train['scannedLineItems'] = train['scannedLineItemsPerSecond'] * train['totalScanTimeInSeconds']\n",
    "train['pricePerScannedLineItem'] = train['grandTotal'] / train['scannedLineItems']\n",
    "train['scansWithoutRegistrationPerScannedLineItem'] = train['scansWithoutRegistration'] / train['scannedLineItems']\n",
    "train['quantityModificationsPerScannedLineItem'] = train['quantityModifications'] / train['scannedLineItems']\n",
    "train['lineItemVoidsPerSecond'] = train['lineItemVoids'] / train['totalScanTimeInSeconds']\n",
    "train['scansWithoutRegistrationPerSecond'] = train['scansWithoutRegistration'] / train['totalScanTimeInSeconds']\n",
    "train['quantityModificationsPerSecond'] = train['quantityModifications'] / train['totalScanTimeInSeconds']\n",
    "train['secondsPerEuro'] = train['totalScanTimeInSeconds'] / train['grandTotal']\n",
    "train['lineItemVoidsPerEuro'] = train['lineItemVoids'] / train['grandTotal']\n",
    "train['scansWithoutRegistrationPerEuro'] = train['scansWithoutRegistration'] / train['grandTotal']\n",
    "train['quantityModificationsPerEuro'] = train['quantityModifications'] / train['grandTotal']\n",
    "\n",
    "test['scannedLineItems'] = test['scannedLineItemsPerSecond'] * test['totalScanTimeInSeconds']\n",
    "test['pricePerScannedLineItem'] = test['grandTotal'] / test['scannedLineItems']\n",
    "test['scansWithoutRegistrationPerScannedLineItem'] = test['scansWithoutRegistration'] / test['scannedLineItems']\n",
    "test['quantityModificationsPerScannedLineItem'] = test['quantityModifications'] / test['scannedLineItems']\n",
    "test['lineItemVoidsPerSecond'] = test['lineItemVoids'] / test['totalScanTimeInSeconds']\n",
    "test['scansWithoutRegistrationPerSecond'] = test['scansWithoutRegistration'] / test['totalScanTimeInSeconds']\n",
    "test['quantityModificationsPerSecond'] = test['quantityModifications'] / test['totalScanTimeInSeconds']\n",
    "test['secondsPerEuro'] = test['totalScanTimeInSeconds'] / test['grandTotal']\n",
    "test['lineItemVoidsPerEuro'] = test['lineItemVoids'] / test['grandTotal']\n",
    "test['scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / test['grandTotal']\n",
    "test['quantityModificationsPerEuro'] = test['quantityModifications'] / test['grandTotal']\n",
    "\n",
    "test.loc[test['grandTotal'] == 0.00, 'secondsPerEuro'] = test['totalScanTimeInSeconds'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'lineItemVoidsPerEuro'] = test['lineItemVoids'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'scansWithoutRegistrationPerEuro'] = test['scansWithoutRegistration'] / 0.01\n",
    "test.loc[test['grandTotal'] == 0.00, 'quantityModificationsPerEuro'] = test['quantityModifications'] / 0.01\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "# Cross validation\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Split *train* dataset to feature and target sets \n",
    "X = train.drop('fraud',axis=1)\n",
    "Y = train['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer \n",
    "\n",
    "feature_scaler = MinMaxScaler()\n",
    "data_train = pd.DataFrame(feature_scaler.fit_transform(X))\n",
    "#feature_scaler = StandardScaler()\n",
    "#X = pd.DataFrame(feature_scaler.fit_transform(X.values), columns=X.columns, index=X.index)\n",
    "#data_preparation = \"StandardScaler\"\n",
    "\n",
    "#transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "#X_scaled = pd.DataFrame(transformer.transform(X), columns=X.columns, index=X.index)\n",
    "#data_preparation = \"LogScaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 1879\n",
      "Homogeneity: -0.000\n",
      "Completeness: 1.000\n",
      "V-measure: -0.000\n",
      "Adjusted Rand Index: 0.000\n",
      "Adjusted Mutual Information: -0.000\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(Y, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels,\n",
    "                                           average_method='arithmetic'))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "#unique_labels = set(labels)\n",
    "#colors = [plt.cm.Spectral(each)\n",
    "#          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "#for k, col in zip(unique_labels, colors):\n",
    "#    if k == -1:\n",
    "#        # Black used for noise.\n",
    "#        col = [0, 0, 0, 1]\n",
    "#\n",
    "#    class_member_mask = (labels == k)\n",
    "#\n",
    "#    xy = X[class_member_mask & core_samples_mask]\n",
    "#    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#             markeredgecolor='k', markersize=14)\n",
    "#\n",
    "#    xy = X[class_member_mask & ~core_samples_mask]\n",
    "#    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "#             markeredgecolor='k', markersize=6)\n",
    "#\n",
    "#plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
